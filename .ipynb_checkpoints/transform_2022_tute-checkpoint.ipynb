{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Geospatial ML Challenges: A prospectivity analysis example\n",
    "\n",
    "This notebook \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# import geospatial data modules\n",
    "import rasterio\n",
    "import geopandas as gpd\n",
    "\n",
    "# set path to data directory\n",
    "data_dir = r'/mnt/c/working/transform_2022/data/'\n",
    "\n",
    "# set paths to key data sets\n",
    "point_fn = os.path.join(data_dir, 'sn_w_minoccs.gpkg')\n",
    "raster_fns = [os.path.join(data_dir, x) for x in os.listdir(data_dir) if '.tif' in x and 'xml' not in x]\n",
    "point_fn, raster_fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the mineral occurences\n",
    "df = gpd.read_file(point_fn)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through geotiff files and read bands into an array\n",
    "data, names = [], []\n",
    "for fn in raster_fns:\n",
    "  with rasterio.open(fn, 'r') as src:\n",
    "    # read the coordinate transform\n",
    "    transf = src.transform\n",
    "    # create an extent tuple containing (xmin, xmax, ymin, ymax) for the rasters\n",
    "    region = (src.bounds.left, src.bounds.right, src.bounds.bottom, src.bounds.top)\n",
    "    # read the data, derive a nodata mask and nullify nodata pixels\n",
    "    d = src.read(1)\n",
    "    nodata_mask = d == src.nodata\n",
    "    d[nodata_mask] = np.nan\n",
    "    # append data to data list and append file names to names list (remove .tif file extension)\n",
    "    data.append(d)\n",
    "    names.append(os.path.basename(fn).split('.')[0])\n",
    "\n",
    "# combine 2D raster arrays into 3D stack, print some details\n",
    "data = np.stack(data)\n",
    "print ('3D (Nbands, Nycolumns, Nxcolumns) data cube shape: {}'.format(data.shape))\n",
    "print ('Geophysical data sets in cube:\\n', names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data sets\n",
    "fig, axes = plt.subplots(2, 4, figsize=(15,10), constrained_layout=True)\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "  if i < data.shape[0]:\n",
    "    ax.imshow(data[i], extent=region, vmin=np.nanpercentile(data[i], 5), vmax=np.nanpercentile(data[i], 95))\n",
    "    df.plot(ax=ax, markersize=150, facecolor='r', color='k', marker='*', linewidth=1)\n",
    "    ax.set(title=names[i])\n",
    "  else:\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the rasterize module\n",
    "from rasterio.features import rasterize\n",
    "\n",
    "# rasterise the occurence points such that pixels within 500m are labelled '1', and all other are labelled '0'\n",
    "labels = rasterize(shapes=((geom,1.) for geom in df.buffer(500).geometry), out_shape=data[0].shape, fill=0., transform=transf)\n",
    "\n",
    "# apply the no data mask\n",
    "labels[nodata_mask] = np.nan\n",
    "\n",
    "# plot the predictions\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.imshow(labels, extent=region, interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape arrays to derive a X (Npixels, Nfeatures) array and y (Npixels) array\n",
    "X_pix = data.reshape((data.shape[0], data.shape[1] * data.shape[2])).T\n",
    "y_pix = labels.flatten()\n",
    "print ('X_pix data array shape is {}, y_pix labels array shape is {}'.format(X_pix.shape, y_pix.shape))\n",
    "\n",
    "# remove nodata pixels from both data sets\n",
    "X = X_pix[~np.isnan(y_pix)]\n",
    "y = y_pix[~np.isnan(y_pix)]\n",
    "print ('X data array shape is {}, y labels array shape is {}'.format(X.shape, y.shape))\n",
    "\n",
    "# summarise the data set\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.bar(0, y[y==0].shape, label='Distal pixels')\n",
    "ax.bar(1, y[y==1].shape, label='Proximal pixels')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualise histograms\n",
    "fig, axes = plt.subplots(2, 4, figsize=(14,8), constrained_layout=True)\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "  if i < data.shape[0]:\n",
    "    bins = np.linspace(np.percentile(X[:,i], 5), np.percentile(X[:,i], 95), 50)\n",
    "    for j, label in zip([0,1], ['Distal','Proximal']):\n",
    "      ax.hist(X[y==j, i], bins=bins, density=True, alpha=0.5, label=label)\n",
    "    ax.legend()\n",
    "    ax.set(title=names[i], ylabel='Probability Density', xlabel='Value')\n",
    "  else:\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import some sci-kit learn modules\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# build a random training and testing split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# define model, fit it to the data\n",
    "model1 = RandomForestClassifier(n_estimators=15, n_jobs=-1)\n",
    "model1.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import reciever operating characteristic curve and area under the curve metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# evaluate the model on the test data set\n",
    "y_preds = model1.predict(X_test)\n",
    "y_proba = model1.predict_proba(X_test)\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_proba[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# visualise this\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.plot(fpr, tpr, label='AUC=%0.2f' % roc_auc)\n",
    "ax.plot([0,1], [0,1], 'r--')\n",
    "ax.set(title='Reciever Operating Characteristic', \n",
    "       ylabel='True Positive Rate', xlabel='False Positive Rate')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get spatial results\n",
    "pred_ar1 = np.zeros_like(data[0].flatten())\n",
    "pred_ar1[~nodata_mask.flatten()] = model1.predict_proba(X)[:,1]\n",
    "pred_ar1[nodata_mask.flatten()] = np.nan\n",
    "pred_ar1 = pred_ar1.reshape(data[0].shape)\n",
    "\n",
    "# plot the predictions\n",
    "fig, ax = plt.subplots(figsize=(13,13))\n",
    "im = ax.imshow(pred_ar1, extent=region, cmap='turbo')\n",
    "fig.colorbar(im, ax=ax, shrink=0.5, label='Probability Proximal')\n",
    "# df.plot(ax=ax, markersize=250, facecolor='w', color='k', marker='*', linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import random undersampling module from imbalanced learn library\n",
    "from imblearn.under_sampling import RandomUnderSampler \n",
    "\n",
    "# stratify the classes with a random undersampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_strat, y_strat = rus.fit_resample(X, y)\n",
    "print ('Before random undersampling:\\n\\t{} class 0 samples vs. {} class 1 samples'.format(len(y_train[y_train==0]), len(y_train[y_train==1])))\n",
    "print ('After random undersampling:\\n\\t{} class 0 samples vs. {} class 1 samples'.format(len(y_strat[y_strat==0]), len(y_strat[y_strat==1])))\n",
    "\n",
    "# build a random training and testing split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_strat, y_strat, test_size=0.33, random_state=42)\n",
    "\n",
    "# define model, fit it to the stratified data data\n",
    "model2 = RandomForestClassifier(n_estimators=15, n_jobs=-1)\n",
    "model2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model on the test data set\n",
    "y_preds = model2.predict_proba(X_test)\n",
    "fpr, tpr, threshold = roc_curve(y_test, y_preds[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# visualise this\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.plot(fpr, tpr, label='AUC=%0.2f' % roc_auc)\n",
    "ax.plot([0,1], [0,1], 'r--')\n",
    "ax.set(title='Reciever Operating Characteristic', \n",
    "       ylabel='True Positive Rate', xlabel='False Positive Rate')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get spatial results\n",
    "pred_ar2 = np.zeros_like(data[0].flatten())\n",
    "pred_ar2[~nodata_mask.flatten()] = model2.predict_proba(X)[:,1]\n",
    "pred_ar2[nodata_mask.flatten()] = np.nan\n",
    "pred_ar2 = pred_ar2.reshape(data[0].shape)\n",
    "\n",
    "# plot the predictions\n",
    "fig, ax = plt.subplots(figsize=(13,13))\n",
    "im = ax.imshow(pred_ar2, extent=region, cmap='turbo')\n",
    "fig.colorbar(im, ax=ax, shrink=0.5, label='Probability Proximal')\n",
    "df.plot(ax=ax, markersize=250, facecolor='w', color='k', marker='*', linewidth=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is better, but the workflow suffers from a critical issue that makes us overestimate model purformance - spatial autocorrelation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define checkerboard function \n",
    "def make_checkerboard(boardsize, squaresize):\n",
    "  '''\n",
    "  props to stackoverflow user Blubberguy22, posted March 17, 2020 at 19:00\n",
    "  https://stackoverflow.com/questions/2169478/how-to-make-a-checkerboard-in-numpy\n",
    "  '''\n",
    "  return np.fromfunction(lambda i, j: (i//squaresize[0])%2 != (j//squaresize[1])%2, boardsize).astype(int)\n",
    "\n",
    "# make a checkerboard, plot it\n",
    "checker = make_checkerboard(data[0].shape, (100,100))\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "ax.imshow(checker, extent=region, interpolation='nearest')\n",
    "df.plot(ax=ax, markersize=150, facecolor='w', color='k', marker='*', linewidth=1)\n",
    "ax.set(title='Pixel Sampling Checkerboard')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split these data into two using the checkerboard\n",
    "X_check0 = X_pix[checker.flatten()==0]\n",
    "y_check0 = y_pix[checker.flatten()==0]\n",
    "\n",
    "X_check1 = X_pix[checker.flatten()==1]\n",
    "y_check1 = y_pix[checker.flatten()==1]\n",
    "\n",
    "# remove nans\n",
    "X_check0 = X_check0[~np.isnan(y_check0)]\n",
    "y_check0 = y_check0[~np.isnan(y_check0)]\n",
    "\n",
    "X_check1 = X_check1[~np.isnan(y_check1)]\n",
    "y_check1 = y_check1[~np.isnan(y_check1)]\n",
    "\n",
    "# print some details\n",
    "print ('Checker 0: X data array shape is {}, y labels array shape is {}'.format(X_check0.shape, y_check0.shape))\n",
    "print ('Checker 1: X data array shape is {}, y labels array shape is {}'.format(X_check1.shape, y_check1.shape))\n",
    "\n",
    "# summarise the data set\n",
    "fig, (ax0, ax1) = plt.subplots(1,2,figsize=(10,5))\n",
    "ax0.bar(0, y_check0[y_check0==0].shape, label='Distal pixels')\n",
    "ax0.bar(1, y_check0[y_check0==1].shape, label='Proximal pixels')\n",
    "ax1.bar(0, y_check1[y_check1==0].shape, label='Distal pixels')\n",
    "ax1.bar(1, y_check1[y_check1==1].shape, label='Proximal pixels')\n",
    "[ax.legend() for ax in [ax0, ax1]]\n",
    "[ax.set(title=t) for ax, t in zip([ax0, ax1], ['Checker 0 Data', 'Checker 1 Data'])]\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stratify the checker data sets\n",
    "X_check0, y_check0 = rus.fit_resample(X_check0, y_check0)\n",
    "X_check1, y_check1 = rus.fit_resample(X_check1, y_check1)\n",
    "\n",
    "# define models fit them to different checkerboard data selections\n",
    "model3 = RandomForestClassifier(n_estimators=15, n_jobs=-1)\n",
    "model3.fit(X_check0, y_check0)\n",
    "\n",
    "model4 = RandomForestClassifier(n_estimators=15, n_jobs=-1)\n",
    "model4.fit(X_check1, y_check1)\n",
    "\n",
    "# evaluate the models on checker data unseen in training\n",
    "roc_data = []\n",
    "for model, X_check, y_check in zip([model3, model4], [X_check1, X_check0], [y_check1, y_check0]):\n",
    "  y_pred = model.predict_proba(X_check)\n",
    "  fpr, tpr, threshold = roc_curve(y_check, y_pred[:,1])\n",
    "  roc_auc = auc(fpr, tpr)\n",
    "  roc_data.append((fpr, tpr, roc_auc))\n",
    "\n",
    "# visualise this\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "for i, (fpr, tpr, roc_auc) in enumerate(roc_data):\n",
    "  ax.plot(fpr, tpr, label='Checker {}\\nAUC={}'.format(i, round(roc_auc,2)))\n",
    "  ax.plot([0,1], [0,1], 'r--')\n",
    "ax.set(title='Reciever Operating Characteristic', \n",
    "       ylabel='True Positive Rate', xlabel='False Positive Rate')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get spatial results\n",
    "pred_ars = []\n",
    "for i, model in enumerate([model3, model4]):\n",
    "  pred_ar = np.zeros_like(data[0].flatten())\n",
    "  pred_ar[~nodata_mask.flatten()] = model.predict_proba(X)[:,1]\n",
    "  pred_ar[nodata_mask.flatten()] = np.nan\n",
    "  pred_ars.append(pred_ar.reshape(data[0].shape))\n",
    "\n",
    "# plot the predictions\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18,13))\n",
    "for i, (ax, t) in enumerate(zip(axes, ['Checker 0', 'Checker 1'])):\n",
    "  im = ax.imshow(pred_ars[i], extent=region, cmap='turbo')\n",
    "  fig.colorbar(im, ax=ax, shrink=0.5, label='Probability Proximal')\n",
    "  df.plot(ax=ax, markersize=150, facecolor='w', color='k', marker='*', linewidth=1)\n",
    "  ax.set(title=t)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mineral Field holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import kmeans clustering module\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# run clustering on the coordinates of the occurences, 8 clusters is about right\n",
    "occ_xypts = [[geom.x, geom.y] for geom in df.geometry]\n",
    "kmeans_obj = KMeans(n_clusters=8, random_state=42).fit(occ_xypts)\n",
    "df.cluster_labels = kmeans_obj.labels_ + 1\n",
    "\n",
    "# visualise the clusters\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.imshow(data[0], extent=region, vmin=np.nanpercentile(data[0], 5), vmax=np.nanpercentile(data[0], 95), alpha=0.5)\n",
    "for i in np.unique(df.cluster_labels):\n",
    "  df[df.cluster_labels==i].plot(ax=ax, markersize=150, marker='*', label='C{}'.format(i))\n",
    "ax.set(title='Spatially Clustered Occurences on Isostatic Residual Bouguer')\n",
    "ax.legend(loc=(1.05,0.4))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rasterize the occurence points by cluster\n",
    "clustermap = rasterize(shapes=((geom,c) for c, geom in zip(df.cluster_labels, df.buffer(500).geometry)), \n",
    "                       out_shape=data[0].shape, fill=0., transform=transf)\n",
    "\n",
    "# apply the no data mask\n",
    "clustermap[nodata_mask] = np.nan\n",
    "\n",
    "# plot the predictions\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "im = ax.imshow(clustermap, extent=region, interpolation='nearest', cmap='turbo')\n",
    "fig.colorbar(im, shrink=0.5, label='Cluste Label ID')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data selection function\n",
    "def cluster_pixel_selection(clustermap, data_cube, class_1_list):\n",
    "  X = data_cube.reshape((data_cube.shape[0], data_cube.shape[1] * data_cube.shape[2])).T\n",
    "  y = clustermap.flatten() \n",
    "  X = X[~np.isnan(y)]\n",
    "  y = y[~np.isnan(y)]\n",
    "  y[np.isin(y, class_1_list)] = 1\n",
    "  y[y!=1] = 0\n",
    "  return X, y\n",
    "\n",
    "# create a function to fit a model to input data\n",
    "def fit_stratifiedrandomforest(X, y):\n",
    "  X, y = rus.fit_resample(X, y)\n",
    "  model = RandomForestClassifier(n_estimators=15, n_jobs=-1)\n",
    "  return model.fit(X, y)\n",
    "\n",
    "# define a function to determine performance on holdout occurence clusters\n",
    "def holdout_roc_auc(clustermap, data_cube, holdout_cluster_list, model_cluster_list, model):\n",
    "  X = data_cube.reshape((data_cube.shape[0], data_cube.shape[1] * data_cube.shape[2])).T\n",
    "  y = clustermap.flatten() \n",
    "  X = X[~np.isnan(y)]\n",
    "  y = y[~np.isnan(y)]\n",
    "  X = X[~np.isin(y, model_cluster_list)]\n",
    "  y = y[~np.isin(y, model_cluster_list)]\n",
    "  y[np.isin(y, holdout_cluster_list)] = 1\n",
    "  # predict onto X\n",
    "  y_pred = model.predict_proba(X)\n",
    "  fpr, tpr, threshold = roc_curve(y, y_pred[:,1])\n",
    "  roc_auc = auc(fpr, tpr)\n",
    "  return fpr, tpr, roc_auc\n",
    "\n",
    "# define a function to generate probability maps from a model\n",
    "def get_proba_map(nodata_mask, data_cube, model):\n",
    "  X = data_cube.reshape((data_cube.shape[0], data_cube.shape[1] * data_cube.shape[2])).T\n",
    "  X = X[~nodata_mask.flatten()]\n",
    "  pred_ar = np.zeros_like(data_cube[0].flatten())\n",
    "  pred_ar[~nodata_mask.flatten()] = model.predict_proba(X)[:,1]\n",
    "  pred_ar[nodata_mask.flatten()] = np.nan\n",
    "  pred_ar = pred_ar.reshape(data_cube[0].shape)\n",
    "  return pred_ar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a model on cluster 1\n",
    "X, y = cluster_pixel_selection(clustermap, data, [1])\n",
    "model = fit_stratifiedrandomforest(X, y)\n",
    "fpr, tpr, roc_auc = holdout_roc_auc(clustermap, data, [2,3,4,5,6,7,8], [1], model)\n",
    "\n",
    "# visualise this\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.plot(fpr, tpr, label='AUC={}'.format(round(roc_auc,2)))\n",
    "ax.plot([0,1], [0,1], 'r--')\n",
    "ax.set(title='Reciever Operating Characteristic', \n",
    "       ylabel='True Positive Rate', xlabel='False Positive Rate')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import progress bar\n",
    "from tqdm import tqdm\n",
    "\n",
    "# loop through clusters\n",
    "models, holdout_clusters = [], []\n",
    "fprs, tprs, roc_aucs = [], [], []\n",
    "for i in tqdm(range(1,9)):\n",
    "  X, y = cluster_pixel_selection(clustermap, data, [j for j in range(1,9) if j!=i])\n",
    "  model = fit_stratifiedrandomforest(X, y)\n",
    "  fpr, tpr, roc_auc = holdout_roc_auc(clustermap, data, [i], [j for j in range(1,9) if j!=i], model)\n",
    "  holdout_clusters.append(i)\n",
    "  models.append(model)\n",
    "  fprs.append(fpr)\n",
    "  tprs.append(tpr)\n",
    "  roc_aucs.append(roc_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot ROC curves for each holdout model\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "for fpr, tpr, roc_auc, hc in zip(fprs, tprs, roc_aucs, holdout_clusters):\n",
    "  ax.plot(fpr, tpr, label='Cluster{}\\nAUC={}'.format(hc, round(roc_auc,2)))\n",
    "  ax.plot([0,1], [0,1], 'r--')\n",
    "  ax.set(title='Reciever Operating Characteristic', \n",
    "         ylabel='True Positive Rate', xlabel='False Positive Rate')\n",
    "  ax.legend(loc=(1.05,0.1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop through models to generate pridction maps\n",
    "prob_maps = []\n",
    "for m in models:\n",
    "  prob_maps.append(get_proba_map(nodata_mask, data, m))\n",
    "prob_maps[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot these probability maps\n",
    "fig, axes = plt.subplots(4, 2, figsize=(15,30), constrained_layout=True)\n",
    "for i, ax in enumerate(axes.flatten()):\n",
    "  if i < len(holdout_clusters):\n",
    "    im = ax.imshow(prob_maps[i], vmin=0, vmax=1, cmap='turbo', extent=region)\n",
    "    fig.colorbar(im, ax=ax, shrink=0.5, label='Probability Proximal')\n",
    "    df[df.cluster_labels!=holdout_clusters[i]].plot(ax=ax, markersize=25, color='k', marker='*', label='Training Occurences')\n",
    "    ax.legend(loc='upper left')\n",
    "    ax.set(title='Occurence Cluster {} Holdout'.format(i+1))\n",
    "  else:\n",
    "    ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature importance\n",
    "fig, ax = plt.subplots(figsize=(10,4))\n",
    "feat_imps = np.array([m.feature_importances_ for m in models])\n",
    "ax.boxplot(feat_imps, labels=names)\n",
    "ax.set(title='Cluster Holdout Model Feature Importance')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources\n",
    "\n",
    "All data sets were sourced from <a href=\"https://www.mrt.tas.gov.au/home\">Mineral Resources Tasmania</a> and <a href=\"https://www.ga.gov.au/\">Geoscience Australia</a>\n",
    "\n",
    "___\n",
    "\n",
    "**LICENCE CONDITIONS**\n",
    "\n",
    "By exporting this data you accept and comply with the terms and conditions set out below:\n",
    "\n",
    "<a href=https://creativecommons.org/licenses/by/3.0/au/Creative>Creative Commons Attribution 3.0 Australia</a> \n",
    "\n",
    "You are free to:\n",
    " - **Share** — copy and redistribute the material in any medium or format\n",
    " - **Adapt** — remix, transform, and build upon the material for any purpose, even commercially.\n",
    "\n",
    "Under the following terms:\n",
    "\n",
    " - **Attribution** — You must give <a href=https://creativecommons.org/licenses/by/3.0/au/>appropriate credit</a>, provide a link to the license, and <a href=https://creativecommons.org/licenses/by/3.0/au/>indicate if changes were made</a>. You may do so in any reasonable manner, but not in any way that suggests the licensor endorses you or your use."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ddde3c07babc53dc58854aefe2e9e24c72c5582b4a554f17e28720a9890a9216"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
